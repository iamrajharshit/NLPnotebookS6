{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f10b6a95",
   "metadata": {
    "id": "f10b6a95"
   },
   "source": [
    "Let's have a quick look at the ðŸ¤— Transformers library features. The library downloads pretrained models for Natural Language Understanding (NLU) tasks, such as analyzing the sentiment of a text, and Natural Language Generation (NLG), such as completing a prompt with new text or translating in another language.\n",
    "\n",
    "First we will see how to easily leverage the pipeline API to quickly use those pretrained models at inference. Then, we will dig a little bit more and see how the library gives you access to those models and helps you preprocess your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56565753",
   "metadata": {
    "id": "56565753",
    "outputId": "0d2a4efb-d8b6-40da-9452-558a622e8def",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\91776\\anaconda3\\lib\\site-packages (4.39.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\91776\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\91776\\anaconda3\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\91776\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\91776\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\91776\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\91776\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\91776\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\91776\\anaconda3\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\91776\\anaconda3\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\91776\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\91776\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\91776\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\91776\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\91776\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91776\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\91776\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91776\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb8f2f6",
   "metadata": {
    "id": "edb8f2f6"
   },
   "source": [
    "# Getting started on a task with a pipeline\n",
    "\n",
    "The easiest way to use a pretrained model on a given task is to use pipeline. ðŸ¤— Transformers provides the following tasks out of the box:\n",
    "\n",
    "Sentiment analysis: is a text positive or negative?\n",
    "Text generation (in English): provide a prompt and the model will generate what follows.\n",
    "Name entity recognition (NER): in an input sentence, label each word with the entity it represents (person, place, etc.)\n",
    "Question answering: provide the model with some context and a question, extract the answer from the context.\n",
    "Filling masked text: given a text with masked words (e.g., replaced by [MASK]), fill the blanks.\n",
    "Summarization: generate a summary of a long text.\n",
    "Translation: translate a text in another language.\n",
    "Feature extraction: return a tensor representation of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddf1b641",
   "metadata": {
    "id": "ddf1b641",
    "outputId": "127b5c33-2a97-4b9a-f2ff-149fb1e4a024"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91776\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\91776\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e305c99",
   "metadata": {
    "id": "9e305c99"
   },
   "source": [
    "By default, the model downloaded for this pipeline is called \"distilbert-base-uncased-finetuned-sst-2-english\". We can look at its model page to get more information about it(https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english). It uses the DistilBERT architecture and has been fine-tuned on a dataset called SST-2 for the sentiment analysis task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39188055",
   "metadata": {
    "id": "39188055",
    "outputId": "044d46ac-aca1-4cb8-ae91-4e920f1e4f0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997994303703308}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('We are very happy to show you the Transformers library.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94457394",
   "metadata": {
    "id": "94457394",
    "outputId": "748d96b3-e4a7-4157-f4c4-de4d7e37a751"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998461008071899}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('The pizza is not that great but the crust is awesome.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "545f022c",
   "metadata": {
    "id": "545f022c",
    "outputId": "041a8f35-deaa-44d5-b12b-f548c0f7bf19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9998202919960022}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('The pizza is very bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f729d69f",
   "metadata": {
    "id": "f729d69f",
    "outputId": "0091756c-793a-4c13-c7ae-7e61f3b8ebb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9897701740264893}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('The pizza may be good or  bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38f22abc",
   "metadata": {
    "id": "38f22abc",
    "outputId": "afdc08d3-a871-4156-e919-a16c84d8d427"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: POSITIVE, with score: 0.9998\n",
      "label: NEGATIVE, with score: 0.5309\n",
      "label: POSITIVE, with score: 0.9996\n"
     ]
    }
   ],
   "source": [
    "results = classifier([\"We are very happy to show you the Transformers library.\",\n",
    "           \"We hope you don't hate it.\", \"I hope you will love to join NLP class\" ])\n",
    "for result in results:\n",
    "    print(f\"label: {result['label']}, with score: {round(result['score'],4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774e176b",
   "metadata": {
    "id": "774e176b"
   },
   "source": [
    "# Finetuned model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99e974c",
   "metadata": {
    "id": "a99e974c"
   },
   "source": [
    "Applying the tags \"French\" and \"text-classification\" gives back a suggestion \"nlptown/bert-base-multilingual-uncased-sentiment\". Let's see how we can use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87d62080",
   "metadata": {
    "id": "87d62080"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f682cd4216b4170898fa4f3c1fb1cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/670M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91776\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\91776\\.cache\\huggingface\\hub\\models--nlptown--bert-base-multilingual-uncased-sentiment. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some layers from the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis', model=\"nlptown/bert-base-multilingual-uncased-sentiment\") #multiple languages can be analyzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a0bdff9",
   "metadata": {
    "id": "7a0bdff9",
    "outputId": "4a2d91d7-9c2b-4915-b8ce-e03855d37d58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '1 star', 'score': 0.6116584539413452}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('The pizza is very bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b43ebd99",
   "metadata": {
    "id": "b43ebd99",
    "outputId": "2a0206f0-5717-4eb4-94b4-9613862e4668"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '5 stars', 'score': 0.6953846216201782}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('The pizza is great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c02f872",
   "metadata": {
    "id": "8c02f872",
    "outputId": "c8eac5ee-175b-4932-a3ec-5536ff966b1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '3 stars', 'score': 0.40696874260902405}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"à¤–à¤¾à¤¨à¤¾ à¤–à¤°à¤¾à¤¬ à¤¹à¥ˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5af5e088-343c-4300-a03f-877d2c63b449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '3 stars', 'score': 0.31204473972320557}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"à¤¯à¥‡ à¤•à¤ªà¤¡à¤¼à¥‡ à¤…à¤šà¥à¤›à¥‡ à¤¹à¥ˆà¤‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd62afe1",
   "metadata": {
    "id": "bd62afe1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '4 stars', 'score': 0.4548669457435608}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('Here chats are good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f44bec-c3de-4ff1-b3a9-8ce50af5ac37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
